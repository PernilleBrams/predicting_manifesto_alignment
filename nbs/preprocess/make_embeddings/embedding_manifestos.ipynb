{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Party Manifestos\n",
    "\n",
    "We want to measure manifesto alignment (distance between party manifestos and respective party utterances over election cycles). The present notebook embeds each manifesto published by each party through the years 1997-2022 using a pre-trained BERT model for Danish language. Output of the code is .npy embedding files to be loaded in in order to derive manifesto alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/Users/pbrams/Desktop/AARHUS_UNIVERSITY/kandidat/data_sci/data_sci_project/predicting_manifesto_alignment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party_Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alternativet</td>\n",
       "      <td>2015</td>\n",
       "      <td>Alternativet Alternativet er klar til valg Dan...</td>\n",
       "      <td>klar valg danmark står tre alvorlige kriser kl...</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alternativet</td>\n",
       "      <td>2019</td>\n",
       "      <td>Vores Politik På denne side finder du Alternat...</td>\n",
       "      <td>politik side finder politik politiske visione...</td>\n",
       "      <td>15879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dansk Folkeparti</td>\n",
       "      <td>1998</td>\n",
       "      <td>UDLÆNDINGEPOLITIKKEN UD med særlove og hovsa-l...</td>\n",
       "      <td>udlændingepolitikken særlove hovsaløsninger fo...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dansk Folkeparti</td>\n",
       "      <td>2001</td>\n",
       "      <td>Fælles værdier – fælles ansvar  Arbejdsprogram...</td>\n",
       "      <td>fælles værdier – fælles ansvar arbejdsprogram ...</td>\n",
       "      <td>19173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dansk Folkeparti</td>\n",
       "      <td>2005</td>\n",
       "      <td>Vi vil have et trygt land Danmark skal være et...</td>\n",
       "      <td>trygt land danmark trygt sikkert sted land bor...</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Venstre</td>\n",
       "      <td>2005</td>\n",
       "      <td>Valgløfter Danmark skal være verdensmestre i v...</td>\n",
       "      <td>valgløfter danmark verdensmestre viden frem af...</td>\n",
       "      <td>1879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Venstre</td>\n",
       "      <td>2007</td>\n",
       "      <td>Valggrundlag Folketingsvalg 13. november 2007 ...</td>\n",
       "      <td>valggrundlag folketingsvalg november endnu bed...</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Venstre</td>\n",
       "      <td>2011</td>\n",
       "      <td>Nye tider. Varig velfærd Der er udskrevet folk...</td>\n",
       "      <td>nye tider varig velfærd udskrevet folketingsva...</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Venstre</td>\n",
       "      <td>2015</td>\n",
       "      <td>DET VIL VENSTRE Ydelser til flygtninge skal ne...</td>\n",
       "      <td>ydelser flygtninge suniveau  gør mindre attrak...</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Venstre</td>\n",
       "      <td>2019</td>\n",
       "      <td>Venstres mærkesager Venstre kæmper for mere fr...</td>\n",
       "      <td>mærkesager kæmper mere frihed stærkere fælless...</td>\n",
       "      <td>1063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Party_Name  Year                                               text  \\\n",
       "0       Alternativet  2015  Alternativet Alternativet er klar til valg Dan...   \n",
       "1       Alternativet  2019  Vores Politik På denne side finder du Alternat...   \n",
       "2   Dansk Folkeparti  1998  UDLÆNDINGEPOLITIKKEN UD med særlove og hovsa-l...   \n",
       "3   Dansk Folkeparti  2001  Fælles værdier – fælles ansvar  Arbejdsprogram...   \n",
       "4   Dansk Folkeparti  2005  Vi vil have et trygt land Danmark skal være et...   \n",
       "..               ...   ...                                                ...   \n",
       "57           Venstre  2005  Valgløfter Danmark skal være verdensmestre i v...   \n",
       "58           Venstre  2007  Valggrundlag Folketingsvalg 13. november 2007 ...   \n",
       "59           Venstre  2011  Nye tider. Varig velfærd Der er udskrevet folk...   \n",
       "60           Venstre  2015  DET VIL VENSTRE Ydelser til flygtninge skal ne...   \n",
       "61           Venstre  2019  Venstres mærkesager Venstre kæmper for mere fr...   \n",
       "\n",
       "                                       processed_text  token_count  \n",
       "0   klar valg danmark står tre alvorlige kriser kl...         1858  \n",
       "1    politik side finder politik politiske visione...        15879  \n",
       "2   udlændingepolitikken særlove hovsaløsninger fo...          288  \n",
       "3   fælles værdier – fælles ansvar arbejdsprogram ...        19173  \n",
       "4   trygt land danmark trygt sikkert sted land bor...          304  \n",
       "..                                                ...          ...  \n",
       "57  valgløfter danmark verdensmestre viden frem af...         1879  \n",
       "58  valggrundlag folketingsvalg november endnu bed...         1169  \n",
       "59  nye tider varig velfærd udskrevet folketingsva...         1729  \n",
       "60  ydelser flygtninge suniveau  gør mindre attrak...          730  \n",
       "61  mærkesager kæmper mere frihed stærkere fælless...         1063  \n",
       "\n",
       "[62 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read merged parliamentary dialogue data in\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"{directory_path}/data/preprocessed/clean/manifestos/clean_manifestos.csv\", sep = \";\")\n",
    "\n",
    "# Drop columns starting with 'Unnamed'\n",
    "df = df.loc[:, ~df.columns.str.startswith('Unnamed')]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed each manifesto\n",
    "We'll treat the embeddings separately for each manifesto for each party. This should allow for a nuanced analysis of each party's adherence to its manifesto independently (with all the caveats that come with that of course)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from danlp.models import load_bert_base_model\n",
    "\n",
    "# Load the Danish BERT model\n",
    "print(\"Starting load of load_bert_base_model()\")\n",
    "model = load_bert_base_model()\n",
    "\n",
    "# Load the corresponding tokenizer\n",
    "print(\"Start load of tokenizer.\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Define the chunk size and overlap\n",
    "CHUNK_SIZE = 512\n",
    "OVERLAP = 50\n",
    "\n",
    "def get_embedding(text, model, tokenizer, chunk_size=CHUNK_SIZE, overlap=OVERLAP):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    #print(f\"Total tokens: {len(tokens)}\")  # Debugging print\n",
    "\n",
    "    if len(tokens) <= chunk_size:\n",
    "        #print(f\"in get_embedding(), chunk is {len(tokens)}, so going to embed\")\n",
    "        _, embedding, _ = model.embed_text(text)\n",
    "        return embedding\n",
    "    else:\n",
    "        chunk_embeddings = []\n",
    "        #print(f\"chunk is {len(tokens)}, so going to chunk\")\n",
    "        for i in range(0, len(tokens), chunk_size - overlap):\n",
    "            end = i + chunk_size\n",
    "            chunk = tokens[i:end] if end <= len(tokens) else tokens[i:]\n",
    "            print(f\"Chunk start: {i}, Chunk end: {end}, Chunk length: {len(chunk)}\")  # Debugging print\n",
    "            \n",
    "            if len(chunk) > chunk_size:\n",
    "                print(f\"Chunk size {len(chunk)} exceeds limit of {chunk_size}. Splitting further.\")  # Debugging print\n",
    "                continue  # Skipping this chunk to ensure it does not exceed the limit\n",
    "\n",
    "            chunk_text = tokenizer.convert_tokens_to_string(chunk)\n",
    "            chunk_tokens = tokenizer.tokenize(chunk_text)\n",
    "            #print(f\"chunk_text token length is {len(chunk_tokens)}, chunk_text is '{chunk_text}'\")  # Debugging print\n",
    "            \n",
    "            if len(chunk_tokens) > chunk_size:\n",
    "                #print(f\"Tokenized chunk_text length {len(chunk_tokens)} exceeds limit of {chunk_size}. Skipping.\")  # Debugging print\n",
    "                continue  # Skip embedding if it still exceeds the token limit\n",
    "\n",
    "            #print(f\"Going to embed chunk_text with token length {len(chunk_tokens)}\")  # Debugging print\n",
    "            _, chunk_embedding, _ = model.embed_text(chunk_text)\n",
    "            chunk_embeddings.append(chunk_embedding)\n",
    "        \n",
    "        # Check if chunk_embeddings is empty\n",
    "        if not chunk_embeddings:\n",
    "            print(\"No valid chunks were processed. Returning None.\")\n",
    "            return None\n",
    "\n",
    "        # Average the embeddings from each chunk\n",
    "        document_embedding = np.mean(np.stack(chunk_embeddings), axis=0)\n",
    "        return document_embedding\n",
    "\n",
    "def save_embedding_speech(embedding, index, date, party_name, output_dir, filenames):\n",
    "    if embedding is None:\n",
    "        #print(f\"Embedding is None for index {index}. Skipping save.\")\n",
    "        return\n",
    "    filename = f\"{index}_{date}_{party_name}.npy\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    np.save(filepath, embedding)\n",
    "    filenames.append(filename)  # Append the filename to the list\n",
    "    print(f\"Saving embedding to {filename}\")  # Debugging print\n",
    "\n",
    "def process_and_save_embeddings(df, model, tokenizer, output_dir):\n",
    "    start_time = time.time()\n",
    "    total_rows = len(df)\n",
    "    filenames = []  # List to store filenames\n",
    "    with tqdm(total=total_rows) as pbar:\n",
    "        for index, row in df.iterrows():\n",
    "            try:\n",
    "                print(f\"Processing row {index}\")  # Debugging print\n",
    "                embedding = get_embedding(row['processed_text'], model, tokenizer)\n",
    "                save_embedding_speech(embedding, index, row['Year'], # this part has been changed now, is 'Date' in the other one\n",
    "                row['Party_Name'], output_dir, filenames)\n",
    "                pbar.update(1)\n",
    "                pbar.set_description(f\"Processed and saved embedding for index {index}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing index {index}: {e}\")\n",
    "                pbar.update(1)\n",
    "    print(f\"Total time elapsed: {time.time() - start_time} seconds.\")\n",
    "    return filenames\n",
    "\n",
    "# Directory for saving embeddings\n",
    "output_dir = f\"{directory_path}/data/preprocessed/embeddings/manifesto_BERT_embeddings_1997_2022\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process and save embeddings for the subset\n",
    "filenames = process_and_save_embeddings(df, model, tokenizer, output_dir)\n",
    "\n",
    "# Add the filenames to the df\n",
    "df['embedding_filename'] = filenames\n",
    "\n",
    "# Saving the updated df to a csv file\n",
    "df.to_csv(f\"{directory_path}/data/preprocessed/clean/manifestos/clean_manifestos_1997_2022_with_embedding_filenames.csv\", index=False)\n",
    "\n",
    "# Take a look\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (politicians_not_people_env)",
   "language": "python",
   "name": "politicians_not_people_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
